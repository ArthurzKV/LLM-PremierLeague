#!/usr/bin/env python3
"""
Quick Performance Test - LLM Premier League (Light Version)
Test r√°pido y econ√≥mico para comparar LOCAL vs CLAUDE AI
"""

import requests
import json
import time
from datetime import datetime
import statistics

API_BASE_URL = "http://localhost:8080/api"

class QuickTester:
    def __init__(self):
        self.results = {
            'timestamp': datetime.now().isoformat(),
            'local_mode': {},
            'claude_mode': {}
        }
    
    def toggle_ai_mode(self, enable: bool) -> bool:
        """Cambiar modo AI"""
        try:
            response = requests.post(f"{API_BASE_URL}/toggle-ai", 
                                   json={"use_claude_ai": enable}, timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def test_endpoint(self, endpoint, payload=None, count=3):
        """Test detallado de un endpoint con m√©tricas precisas"""
        times = []
        success = 0
        errors = []
        
        print(f"    üîç Ejecutando {count} requests...")
        start_batch = time.time()
        
        for i in range(count):
            start = time.time()
            try:
                if payload:
                    response = requests.post(f"{API_BASE_URL}/{endpoint}", 
                                           json=payload, timeout=15)
                else:
                    response = requests.get(f"{API_BASE_URL}/{endpoint}", timeout=15)
                
                response_time = time.time() - start
                
                if response.status_code == 200:
                    success += 1
                    times.append(response_time)
                    response_size = len(response.content)
                    print(f"      {i+1}/{count}: ‚úÖ {response_time:.3f}s ({response_size} bytes)")
                else:
                    errors.append(f"HTTP {response.status_code}")
                    print(f"      {i+1}/{count}: ‚ùå HTTP {response.status_code}")
                    
            except Exception as e:
                error_msg = str(e)[:50]
                errors.append(error_msg)
                print(f"      {i+1}/{count}: ‚ùå {error_msg}")
            
            time.sleep(0.3)  # Pausa m√°s corta
        
        batch_time = time.time() - start_batch
        
        # Calcular estad√≠sticas detalladas
        result = {
            'avg_time': statistics.mean(times) if times else 999,
            'min_time': min(times) if times else 0,
            'max_time': max(times) if times else 0,
            'success_rate': success / count,
            'total_tests': count,
            'successful_tests': success,
            'failed_tests': count - success,
            'batch_duration': batch_time,
            'throughput': count / batch_time,
            'errors': errors
        }
        
        # Mostrar resumen del endpoint
        print(f"    üìä Resumen: {success}/{count} exitosos, promedio {result['avg_time']:.3f}s")
        
        return result
    
    def run_quick_test(self):
        """Test detallado de 8 minutos m√°ximo con comparaciones precisas"""
        print("üöÄ DETAILED QUICK TEST - LLM Premier League")
        print("=" * 65)
        print("‚è±Ô∏è  Duraci√≥n estimada: 6-8 minutos")
        print("üí∞ Costo: ~12 requests totales (6 por modo)")
        
        # Test endpoints importantes (solo los cr√≠ticos)
        tests = [
            ('health', 'Health Check', None),
            ('predict', 'Prediction', {'home_team': 'Arsenal', 'away_team': 'Chelsea'}),
            ('chat', 'Chat', {'message': '¬øQui√©n ganar√° la Premier League?'})
        ]
        
        # Test LOCAL mode (AI OFF)
        print(f"\nüè† TESTING LOCAL MODE (AI OFF)")
        print("=" * 45)
        start_local = time.time()
        
        if self.toggle_ai_mode(False):
            print("‚úÖ Modo LOCAL activado")
            time.sleep(1)
            self.results['local_mode'] = {}
            
            for endpoint, name, payload in tests:
                print(f"\n  üìä {name} Test:")
                self.results['local_mode'][endpoint] = self.test_endpoint(endpoint, payload, 2)
        else:
            print("‚ùå Error activando modo LOCAL")
            
        local_duration = time.time() - start_local
        print(f"\n‚è±Ô∏è  Tiempo total LOCAL: {local_duration:.2f}s")
        
        time.sleep(2)  # Pausa entre modos
        
        # Test CLAUDE AI mode (AI ON)
        print(f"\nü§ñ TESTING CLAUDE AI MODE (AI ON)")
        print("=" * 45)
        start_claude = time.time()
        
        if self.toggle_ai_mode(True):
            print("‚úÖ Modo CLAUDE AI activado")
            time.sleep(1)
            self.results['claude_mode'] = {}
            
            for endpoint, name, payload in tests:
                print(f"\n  üìä {name} Test:")
                self.results['claude_mode'][endpoint] = self.test_endpoint(endpoint, payload, 2)
        else:
            print("‚ùå Error activando modo CLAUDE AI")
            
        claude_duration = time.time() - start_claude
        print(f"\n‚è±Ô∏è  Tiempo total CLAUDE AI: {claude_duration:.2f}s")
        
        # Guardar duraciones totales
        self.results['mode_durations'] = {
            'local_total': local_duration,
            'claude_total': claude_duration
        }
    
    def print_summary(self):
        """Resumen detallado con comparaciones precisas"""
        print("\n" + "=" * 70)
        print("üìä DETAILED PERFORMANCE COMPARISON")
        print("=" * 70)
        
        local = self.results['local_mode']
        claude = self.results['claude_mode']
        durations = self.results.get('mode_durations', {})
        
        # Tabla comparativa detallada
        print(f"\n{'Endpoint':<12} {'LOCAL (OFF)':<20} {'CLAUDE AI (ON)':<20} {'Winner':<10}")
        print("-" * 70)
        
        endpoint_winners = {}
        
        for endpoint in local.keys():
            if endpoint in claude:
                local_time = local[endpoint]['avg_time']
                claude_time = claude[endpoint]['avg_time']
                local_success = local[endpoint]['success_rate']
                claude_success = claude[endpoint]['success_rate']
                
                # Determinar ganador por velocidad
                speed_winner = "LOCAL" if local_time < claude_time else "CLAUDE AI"
                reliability_winner = "LOCAL" if local_success > claude_success else "CLAUDE AI"
                
                endpoint_winners[endpoint] = {
                    'speed': speed_winner,
                    'reliability': reliability_winner
                }
                
                print(f"{endpoint:<12} {local_time:.3f}s ({local_success*100:3.0f}%) {claude_time:>8.3f}s ({claude_success*100:3.0f}%) {speed_winner:>10}")
        
        # Estad√≠sticas generales
        print(f"\nüìà ESTAD√çSTICAS GENERALES:")
        print("-" * 40)
        
        # Tiempos promedio
        local_avg = sum(r['avg_time'] for r in local.values()) / len(local)
        claude_avg = sum(r['avg_time'] for r in claude.values()) / len(claude)
        speed_diff = abs(local_avg - claude_avg)
        speed_improvement = ((max(local_avg, claude_avg) - min(local_avg, claude_avg)) / max(local_avg, claude_avg)) * 100
        
        print(f"‚ö° Velocidad promedio:")
        print(f"   ‚Ä¢ LOCAL: {local_avg:.3f}s")
        print(f"   ‚Ä¢ CLAUDE AI: {claude_avg:.3f}s")
        print(f"   ‚Ä¢ Diferencia: {speed_diff:.3f}s ({speed_improvement:.1f}% {'LOCAL' if local_avg < claude_avg else 'CLAUDE AI'} m√°s r√°pido)")
        
        # Tasas de √©xito
        local_success_avg = sum(r['success_rate'] for r in local.values()) / len(local)
        claude_success_avg = sum(r['success_rate'] for r in claude.values()) / len(claude)
        
        print(f"\n‚úÖ Confiabilidad promedio:")
        print(f"   ‚Ä¢ LOCAL: {local_success_avg*100:.1f}%")
        print(f"   ‚Ä¢ CLAUDE AI: {claude_success_avg*100:.1f}%")
        
        # Duraci√≥n total de tests
        if durations:
            print(f"\n‚è±Ô∏è  Duraci√≥n de testing:")
            print(f"   ‚Ä¢ LOCAL: {durations['local_total']:.1f}s")
            print(f"   ‚Ä¢ CLAUDE AI: {durations['claude_total']:.1f}s")
        
        # Recomendaciones detalladas
        print(f"\nüéØ RECOMENDACIONES:")
        print("-" * 30)
        
        speed_wins = sum(1 for w in endpoint_winners.values() if w['speed'] == 'LOCAL')
        
        if speed_wins >= 2:
            print("üöÄ LOCAL MODE es consistentemente m√°s r√°pido")
            print("   ‚Üí Ideal para aplicaciones que requieren baja latencia")
            print("   ‚Üí Perfecto para endpoints de alta frecuencia")
        else:
            print("ü§ñ CLAUDE AI competitive en velocidad")
            print("   ‚Üí Acceptable para la mayor√≠a de casos de uso")
        
        if claude_success_avg >= local_success_avg:
            print("üéØ CLAUDE AI ofrece mejor confiabilidad")
            print("   ‚Üí Recomendado para casos cr√≠ticos")
        
        # Recomendaci√≥n final
        print(f"\nüèÜ VEREDICTO FINAL:")
        if local_avg < claude_avg and local_success_avg >= claude_success_avg - 0.1:
            print("   üí° LOCAL MODE: Mejor opci√≥n general (velocidad + confiabilidad)")
        elif claude_success_avg > local_success_avg + 0.1:
            print("   üí° CLAUDE AI: Mejor para casos que requieren m√°xima precision")
        else:
            print("   üí° H√çBRIDO: Usar LOCAL para velocidad, CLAUDE AI para calidad")
    
    def save_results(self):
        """Guardar resultados b√°sicos"""
        filename = f"quick_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        filepath = f"/Users/rios/Desktop/LLM-PREMIER/testing/{filename}"
        
        with open(filepath, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"\nüíæ Resultados guardados en: {filename}")

def main():
    print("‚ö° DETAILED TESTING - An√°lisis preciso con consumo moderado")
    print("‚è±Ô∏è  Duraci√≥n: ~6-8 minutos")
    print("üí∞ Costo: ~12 requests (6 LOCAL + 6 CLAUDE AI)")
    print("üéØ Comparaci√≥n detallada: ON vs OFF con m√©tricas precisas")
    print()
    
    tester = QuickTester()
    tester.run_quick_test()
    tester.print_summary()
    tester.save_results()
    
    print(f"\nüéâ An√°lisis detallado completado!")
    print(f"üìä Datos precisos para tomar decisiones informadas")
    print(f"üí∏ Balance perfecto: detalle √∫til sin quebrar el wallet")

if __name__ == "__main__":
    main()
